{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sc\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import sklearn.model_selection\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC_SIZE=64\n",
    "N_TRAIN=70\n",
    "N_TEST=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['images']\n",
    "Y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dig = np.random.choice(data['target_names'])\n",
    "ref_dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ims = c\n",
    "other_ims = X[Y!=ref_dig]\n",
    "# other_dig = Y[Y!=ref_dig]\n",
    "\n",
    "Xt=ref_ims[np.random.choice(ref_ims.shape[0],\n",
    "                            size=100, replace=False)]\n",
    "Xt_train = Xt[:N_TRAIN].reshape(N_TRAIN, PIC_SIZE)\n",
    "Xt_test = Xt[N_TRAIN:].reshape(N_TEST, PIC_SIZE)\n",
    "Yt_train=np.ones((N_TRAIN))\n",
    "Yt_test=np.ones((N_TEST))\n",
    "\n",
    "Xf=other_ims[np.random.choice(other_ims.shape[0],\n",
    "                            size=100, replace=False)]\n",
    "Xf_train = Xf[:N_TRAIN].reshape(N_TRAIN, PIC_SIZE)\n",
    "Xf_test = Xf[N_TRAIN:].reshape(N_TEST, PIC_SIZE)\n",
    "Yf_train=np.zeros((N_TRAIN))\n",
    "Yf_test=np.zeros((N_TEST))\n",
    "\n",
    "X_train = np.concatenate((Xt_train, Xf_train),axis=0)\n",
    "Y_train = np.concatenate((Yt_train, Yf_train),axis=0)\n",
    "\n",
    "X_test = np.concatenate((Xt_test, Xf_test),axis=0)\n",
    "Y_test = np.concatenate((Yt_test, Yf_test),axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 16\n",
    "X_test /= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(gamma='scale', probability=True)#,kernel=\"poly\")\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kf_valid(Xf,Xt, reg, kernel, degree=3):\n",
    "    X = np.concatenate((Xf,Xt)).reshape(-1, PIC_SIZE)\n",
    "    Y = np.concatenate((np.zeros(100),np.ones(100)))\n",
    "    kf = sklearn.model_selection.KFold(10,True)\n",
    "    FAR = 0\n",
    "    FRR = 0\n",
    "    ll = 0\n",
    "    Fs = 0\n",
    "    for i in kf.split(X, Y):\n",
    "        X_tr = X[i[0]]\n",
    "        Y_tr = Y[i[0]]\n",
    "        X_te = X[i[1]].astype(int)\n",
    "        Y_te = Y[i[1]].astype(int)\n",
    "        model = svm.SVC(gamma='scale', probability=True, \n",
    "                        C=reg, kernel=kernel, degree=degree)\n",
    "        model.fit(X_tr,Y_tr)\n",
    "        Y_pred = model.predict(X_te).astype(int)\n",
    "        Y_prob = model.predict_proba(X_te)\n",
    "        ll += metrics.log_loss(Y_te,Y_prob)\n",
    "        Fs += metrics.f1_score(Y_te,Y_pred)\n",
    "        tp = np.sum(Y_pred & Y_te)\n",
    "        tn = np.sum(np.logical_not(Y_pred) & np.logical_not(Y_te))\n",
    "        fp = np.sum(Y_pred & np.logical_not(Y_te))\n",
    "        fn = np.sum(np.logical_not(Y_pred) & Y_te)\n",
    "\n",
    "        FAR += fp/np.sum(Y_te==0)\n",
    "        FRR += fn/np.sum(Y_te==1)\n",
    "    return FAR,FRR,ll,Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:49<00:00,  9.92s/it]\n"
     ]
    }
   ],
   "source": [
    "options={}\n",
    "for i in tqdm.tqdm(kernels, position=0, leave=True):\n",
    "    losses=[]\n",
    "    for j in np.arange(0.1, 10, 0.1):\n",
    "        losses.append(kf_valid(Xf, Xt, j, i[0], i[1]))\n",
    "    losses=np.array(losses)\n",
    "    options[i]=np.concatenate((np.min(losses[:,:3],axis=0),10-np.max(losses[:,3],keepdims=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('linear', 3)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.zeros(4)\n",
    "stds = np.zeros(4)\n",
    "m = []\n",
    "keys = list(options.keys())\n",
    "for i in keys:\n",
    "    m.append(options[i])\n",
    "m=np.array(m)\n",
    "means = np.mean(m,axis=0)\n",
    "stds = np.std(m,axis=0)\n",
    "m=(m-means)/stds\n",
    "keys[np.argmin(np.sum(m,axis=1,keepdims=True))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лінійна SVM показала кращий середній резутьат по цим метрикам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [01:18<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кращий результат при регуляризації 7.2299999999999995: FRR = 0.0, FAR = 0.03333333333333333, log-loss = 0.07079869392194241, F-score = 0.9836065573770492\n"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "for i in tqdm.tqdm(np.arange(0.01, 10, 0.01),position=0, leave=True):\n",
    "    losses.append(kf_valid(Xf,Xt, i, keys[np.argmin(np.sum(m,axis=1,keepdims=True))][0],\n",
    "                           keys[np.argmin(np.sum(m,axis=1,keepdims=True))][1]))\n",
    "    \n",
    "losses=np.array(losses)\n",
    "\n",
    "means = np.mean(losses,axis=0)\n",
    "stds = np.std(losses,axis=0)\n",
    "norm_losses=(losses-means)/stds\n",
    "\n",
    "best = np.argmin(np.sum(norm_losses,axis=1,keepdims=True))\n",
    "\n",
    "model = svm.SVC(gamma='scale', probability=True, \n",
    "                C=np.arange(0.01, 10, 0.01)[best],\n",
    "                kernel=keys[np.argmin(np.sum(m,axis=1,keepdims=True))][0],\n",
    "                degree=keys[np.argmin(np.sum(m,axis=1,keepdims=True))][1]\n",
    "               )\n",
    "\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test).astype(int)\n",
    "Y_prob = model.predict_proba(X_test)\n",
    "ll = metrics.log_loss(Y_test,Y_prob)\n",
    "Fs = metrics.f1_score(Y_test,Y_pred)\n",
    "tp = np.sum(Y_pred & Y_test)\n",
    "tn = np.sum(np.logical_not(Y_pred) & np.logical_not(Y_test))\n",
    "fp = np.sum(Y_pred & np.logical_not(Y_test))\n",
    "fn = np.sum(np.logical_not(Y_pred) & Y_test)\n",
    "FAR = fp/np.sum(Y_test==0)\n",
    "FRR = fn/np.sum(Y_test==1)\n",
    "\n",
    "print(\"Кращий результат при регуляризації {}: FRR = {}, FAR = {}, log-loss = {}, F-score = {}\".format(\n",
    "    np.arange(0.01, 10, 0.01)[best], FRR, FAR, ll, Fs\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Та ж сама модельна зашумлених данних: FRR = 0.23333333333333334, FAR = 0.13333333333333333, log-loss = 0.57014711766603, F-score = 0.8070175438596491\n"
     ]
    }
   ],
   "source": [
    "noise = sc.norm.rvs(0,0.2**0.5, (N_TEST*2, PIC_SIZE))\n",
    "X_test_noised = noise+X_test\n",
    "# X_test_noised=(X_test_noised-np.min(X_test_noised))/(np.max(X_test_noised)-np.min(X_test_noised))\n",
    "Y_pred = model.predict(X_test_noised).astype(int)\n",
    "Y_prob = model.predict_proba(X_test_noised)\n",
    "ll = metrics.log_loss(Y_test,Y_prob)\n",
    "Fs = metrics.f1_score(Y_test,Y_pred)\n",
    "tp = np.sum(Y_pred & Y_test)\n",
    "tn = np.sum(np.logical_not(Y_pred) & np.logical_not(Y_test))\n",
    "fp = np.sum(Y_pred & np.logical_not(Y_test))\n",
    "fn = np.sum(np.logical_not(Y_pred) & Y_test)\n",
    "FAR = fp/np.sum(Y_test==0)\n",
    "FRR = fn/np.sum(Y_test==1)\n",
    "print(\"Та ж сама модельна зашумлених данних: FRR = {}, FAR = {}, log-loss = {}, F-score = {}\".format(\n",
    "    FRR, FAR, ll, Fs\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вікно розміром 3: FRR = 0.16666666666666666, FAR = 0.0, log-loss = 0.28820068675319, F-score = 0.9090909090909091\n",
      "вікно розміром 5: FRR = 0.16666666666666666, FAR = 0.0, log-loss = 0.2918095799138572, F-score = 0.9090909090909091\n",
      "вікно розміром 7: FRR = 0.36666666666666664, FAR = 0.0, log-loss = 0.44170541440356775, F-score = 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "for i in range(3,9,2):\n",
    "    X_test_denoised = ndimage.median_filter(X_test_noised,size=i)\n",
    "#     X_test_denoised=(X_test_denoised-np.min(X_test_denoised))/(np.max(X_test_denoised)-np.min(X_test_denoised))\n",
    "    Y_pred = model.predict(X_test_denoised).astype(int)\n",
    "    Y_prob = model.predict_proba(X_test_denoised)\n",
    "    ll = metrics.log_loss(Y_test,Y_prob)\n",
    "    Fs = metrics.f1_score(Y_test,Y_pred)\n",
    "    tp = np.sum(Y_pred & Y_test)\n",
    "    tn = np.sum(np.logical_not(Y_pred) & np.logical_not(Y_test))\n",
    "    fp = np.sum(Y_pred & np.logical_not(Y_test))\n",
    "    fn = np.sum(np.logical_not(Y_pred) & Y_test)\n",
    "    FAR = fp/np.sum(Y_test==0)\n",
    "    FRR = fn/np.sum(Y_test==1)\n",
    "    losses.append([FRR,FAR,ll,Fs])\n",
    "size=3\n",
    "for i in losses:\n",
    "    print(\"вікно розміром {}: FRR = {}, FAR = {}, log-loss = {}, F-score = {}\".format(size,*i))\n",
    "    size+=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "З результатов видно, що фільтр з розмвром вікна 3 спрацював краще за інші"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = X[Y==0]\n",
    "pick = np.random.choice(cur.shape[0], size=100, replace=False)\n",
    "X_train = cur[pick][:N_TRAIN]\n",
    "X_test = cur[pick][N_TRAIN:]\n",
    "Y_train = np.ones(N_TRAIN)*0\n",
    "Y_test = np.ones(N_TEST)*0\n",
    "for i in data['target_names'][1:]:\n",
    "    cur = X[Y==i]\n",
    "    pick = np.random.choice(cur.shape[0], size=100, replace=False)\n",
    "    X_train = np.concatenate((X_train,cur[pick][:N_TRAIN]))\n",
    "    X_test = np.concatenate((X_test,cur[pick][N_TRAIN:]))\n",
    "    Y_train = np.concatenate((Y_train,np.ones(N_TRAIN)*i))\n",
    "    Y_test = np.concatenate((Y_test,np.ones(N_TEST)*i))\n",
    "X_train=X_train.reshape(-1,PIC_SIZE)/16\n",
    "X_test=X_test.reshape(-1,PIC_SIZE)/16\n",
    "Y_train=Y_train.astype(int)\n",
    "Y_test=Y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Багатокласовий класифікатор: FRR = 0.0, FAR = 0.0, log-loss = 0.16935017108572942, F-score = 0.9698895238678756\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(gamma='scale', probability=True, \n",
    "                C=np.arange(0.01, 10, 0.01)[best],\n",
    "                kernel=keys[np.argmin(np.sum(m,axis=1,keepdims=True))][0],\n",
    "                degree=keys[np.argmin(np.sum(m,axis=1,keepdims=True))][1],\n",
    "                decision_function_shape = 'ovr'\n",
    "               )\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test).astype(int)\n",
    "Y_prob = model.predict_proba(X_test)\n",
    "ll = metrics.log_loss(Y_test,Y_prob)\n",
    "Fs = metrics.f1_score(Y_test,Y_pred,average=\"weighted\")\n",
    "tp = np.sum(Y_pred & Y_test)\n",
    "tn = np.sum(np.logical_not(Y_pred) & np.logical_not(Y_test))\n",
    "fp = np.sum(Y_pred & np.logical_not(Y_test))\n",
    "fn = np.sum(np.logical_not(Y_pred) & Y_test)\n",
    "FAR = fp/np.sum(Y_test==0)\n",
    "FRR = fn/np.sum(Y_test==1)\n",
    "print(\"Багатокласовий класифікатор: FRR = {}, FAR = {}, log-loss = {}, F-score = {}\".format(FRR, FAR, ll, Fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Багатокласовий класифікатор з зашумленими данними: FRR = 0.1, FAR = 0.06666666666666667, log-loss = 0.8531948689190054, F-score = 0.6916514668615735\n"
     ]
    }
   ],
   "source": [
    "noise = sc.norm.rvs(0,0.2**0.5, (N_TEST*10, PIC_SIZE))\n",
    "X_test_noised = noise+X_test\n",
    "\n",
    "Y_pred = model.predict(X_test_noised).astype(int)\n",
    "Y_prob = model.predict_proba(X_test_noised)\n",
    "ll = metrics.log_loss(Y_test,Y_prob)\n",
    "Fs = metrics.f1_score(Y_test,Y_pred,average=\"weighted\")\n",
    "tp = np.sum(Y_pred & Y_test)\n",
    "tn = np.sum(np.logical_not(Y_pred) & np.logical_not(Y_test))\n",
    "fp = np.sum(Y_pred & np.logical_not(Y_test))\n",
    "fn = np.sum(np.logical_not(Y_pred) & Y_test)\n",
    "FAR = fp/np.sum(Y_test==0)\n",
    "FRR = fn/np.sum(Y_test==1)\n",
    "print(\"Багатокласовий класифікатор з зашумленими данними: FRR = {}, FAR = {}, log-loss = {}, F-score = {}\".format(FRR, FAR, ll, Fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\valer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вікно розміром 3: FRR = 0.0, FAR = 0.26666666666666666, log-loss = 0.8062156518766509, F-score = 0.7444899004878585\n",
      "вікно розміром 5: FRR = 0.0, FAR = 0.16666666666666666, log-loss = 1.4573908421039072, F-score = 0.4451216308930037\n",
      "вікно розміром 7: FRR = 0.0, FAR = 0.3333333333333333, log-loss = 1.715787809911739, F-score = 0.2075360652381829\n"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "for i in range(3,9,2):\n",
    "    X_test_denoised = ndimage.median_filter(X_test_noised,size=i)\n",
    "#     X_test_denoised=(X_test_denoised-np.min(X_test_denoised))/(np.max(X_test_denoised)-np.min(X_test_denoised))\n",
    "    Y_pred = model.predict(X_test_denoised).astype(int)\n",
    "    Y_prob = model.predict_proba(X_test_denoised)\n",
    "    ll = metrics.log_loss(Y_test,Y_prob)\n",
    "    Fs = metrics.f1_score(Y_test,Y_pred, average=\"weighted\")\n",
    "    tp = np.sum(Y_pred & Y_test)\n",
    "    tn = np.sum(np.logical_not(Y_pred) & np.logical_not(Y_test))\n",
    "    fp = np.sum(Y_pred & np.logical_not(Y_test))\n",
    "    fn = np.sum(np.logical_not(Y_pred) & Y_test)\n",
    "    FAR = fp/np.sum(Y_test==0)\n",
    "    FRR = fn/np.sum(Y_test==1)\n",
    "    losses.append([FRR,FAR,ll,Fs])\n",
    "size=3\n",
    "for i in losses:\n",
    "    print(\"вікно розміром {}: FRR = {}, FAR = {}, log-loss = {}, F-score = {}\".format(size,*i))\n",
    "    size+=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знов фільтр з розмвром вікна 3 спрацював краще за інші. Але вийшло навіть гірше, ніж було до видалення шумів. Схоже, що разом із шумом ми видалили корисну інформацію "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
